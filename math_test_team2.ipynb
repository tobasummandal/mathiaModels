{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c01160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeb84fa",
   "metadata": {},
   "source": [
    "# Test Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640e91d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE WITH TEST DATASET FILE PATHS\n",
    "df_main = pd.read_csv(\"./raw_data/training_set_with_formatted_time.csv\")\n",
    "df_ws = pd.read_csv(\"./raw_data/workspace_summary_train.csv\")\n",
    "df_scores = pd.read_csv(\"./raw_data/student_scores_train.csv\")\n",
    "\n",
    "df_main.drop_duplicates(inplace=True)\n",
    "df_ws.drop_duplicates(inplace=True)\n",
    "df_scores.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7757e748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns\n",
    "df_main.drop(columns=['CF..Anon.School.Id.', 'CF..Anon.Class.Id.', 'Time', 'formatted_time'], inplace=True)\n",
    "\n",
    "# Remove rows containing 'OK_AMBIGUOUS'\n",
    "df_main = df_main[df_main['Outcome'] != 'OK_AMBIGUOUS']\n",
    "\n",
    "df_main.sort_values(by=['Anon.Student.Id', 'datetime'], inplace=True)\n",
    "\n",
    "df_main['datetime'] = pd.to_datetime(\n",
    "    df_main['datetime'],\n",
    "    infer_datetime_format=True,\n",
    "    errors='coerce'       # turns invalid parses into NaT\n",
    ")\n",
    "\n",
    "# Generate time steps\n",
    "df_main['time_step'] = df_main.groupby('Anon.Student.Id')['datetime'].rank(method='first') - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aa9d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE WITH TEST DESIRED FILE PATHS\n",
    "df_main.to_csv('preprocessed_data/df_main_allws.csv', index=False)\n",
    "df_ws.to_csv('preprocessed_data/df_ws_allws.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef06ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_ids_to_remove = [\n",
    "    'worksheet_grapher_a1_lin_mod_mult_rep',\n",
    "    'equation_line_2',\n",
    "    'analyzing_models_2step_rationals',\n",
    "    'multiple_representations_of_linear_functions',\n",
    "    'worksheet_grapher_a1_slope_intercept_integer',\n",
    "    'worksheet_grapher_a1_slope_intercept_decimal',\n",
    "    'connecting_slope_intercept_and_point_slope_forms',\n",
    "    'equation_line_1',\n",
    "    'equation_line_3',\n",
    "    'worksheet_grapher_a1_mod_initial_plus_point',\n",
    "    'worksheet_grapher_a1_mod_two_points',\n",
    "    'modeling_linear_equations_in_standard_form',\n",
    "    'graph_setup_linear_equation-1',\n",
    "    'graph_setup_linear_equation-2',\n",
    "    'classifying_relations_and_functions',\n",
    "    'introduction_to_functions',\n",
    "    'graphs_of_functions',\n",
    "    'graphs_of_functions-1',\n",
    "    'compare_functions_diff_reps_linear_relationships'\n",
    "]\n",
    "\n",
    "\n",
    "df_main = df_main[~df_main['Level..Workspace.Id.'].isin(workspace_ids_to_remove)]\n",
    "df_ws = df_ws[~df_ws['workspace'].isin(workspace_ids_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe2dc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned_math = df_scores[[\"Anon.Student.Id\", \"PreMath\", \"PostMath\"]].copy()\n",
    "df_cleaned_math = df_cleaned_math.dropna(subset=[\"PostMath\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c64748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE WITH DESIRED FILE PATHS\n",
    "df_main.to_csv(\"preprocessed_data/df_main.csv\", index=False)\n",
    "df_ws.to_csv(\"preprocessed_data/df_ws.csv\", index=False)\n",
    "df_scores.to_csv(\"preprocessed_data/df_scores.csv\", index=False)\n",
    "df_cleaned_math.to_csv(\"preprocessed_data/df_cleaned_math.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e89e1a",
   "metadata": {},
   "source": [
    "# Loading Preprocessed Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3d1701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "print(\"Loading datasets...\")\n",
    "\n",
    "# Load math scores (target variable)\n",
    "math_scores = pd.read_csv('preprocessed_data/df_cleaned_math.csv')\n",
    "print(f\"Math scores dataset shape: {math_scores.shape}\")\n",
    "\n",
    "# Load workspace behavioral data\n",
    "workspace_data = pd.read_csv('preprocessed_data/df_ws.csv')\n",
    "print(f\"Workspace data shape: {workspace_data.shape}\")\n",
    "\n",
    "# Load main interaction data for help levels\n",
    "main_data = pd.read_csv('preprocessed_data/df_main.csv')\n",
    "print(f\"Main interaction data shape: {main_data.shape}\")\n",
    "\n",
    "print(\"\\nDatasets loaded successfully!\")S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6308f45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering: Calculate student-level aggregated features\n",
    "print(\"Creating behavioral features...\")\n",
    "\n",
    "# Group workspace data by student\n",
    "student_features = workspace_data.groupby('Anon.Student.Id').agg({\n",
    "    # Basic counts and totals\n",
    "    'problems_completed': ['sum', 'mean'],\n",
    "    'hint_count': ['sum', 'mean'],\n",
    "    'error_count': ['sum', 'mean'],\n",
    "    'skills_encountered': ['sum', 'mean'],\n",
    "    'skills_mastered': ['sum', 'mean'],\n",
    "    'workspace_total_time_seconds': ['sum', 'mean', 'std'],\n",
    "    'workspace_progress_status': 'count'  # Total workspaces\n",
    "}).round(4)\n",
    "\n",
    "# Flatten column names\n",
    "student_features.columns = ['_'.join(col).strip() for col in student_features.columns]\n",
    "\n",
    "# Calculate derived features\n",
    "print(\"Calculating derived behavioral features...\")\n",
    "\n",
    "# Error rates\n",
    "student_features['total_error_rate'] = (\n",
    "    student_features['error_count_sum'] / \n",
    "    (student_features['error_count_sum'] + student_features['problems_completed_sum'])\n",
    ").fillna(0)\n",
    "\n",
    "student_features['avg_error_rate'] = (\n",
    "    student_features['error_count_sum'] / student_features['problems_completed_sum']\n",
    ").fillna(0)\n",
    "\n",
    "# Hint request rates\n",
    "student_features['hint_request_rate'] = (\n",
    "    student_features['hint_count_sum'] / student_features['problems_completed_sum']\n",
    ").fillna(0)\n",
    "\n",
    "# Skills mastery rate\n",
    "student_features['skills_mastery_rate'] = (\n",
    "    student_features['skills_mastered_sum'] / student_features['skills_encountered_sum']\n",
    ").fillna(0)\n",
    "\n",
    "# Workspace completion analysis\n",
    "workspace_completion = workspace_data.groupby('Anon.Student.Id').agg({\n",
    "    'workspace_progress_status': lambda x: (x == 'GRADUATED').sum(),\n",
    "    'Anon.Student.Id': 'count'\n",
    "})\n",
    "workspace_completion.columns = ['graduated_workspaces', 'total_workspaces']\n",
    "workspace_completion['workspace_completion_rate'] = (\n",
    "    workspace_completion['graduated_workspaces'] / workspace_completion['total_workspaces']\n",
    ")\n",
    "\n",
    "# Merge completion rates\n",
    "student_features = student_features.join(workspace_completion[['workspace_completion_rate']], how='left')\n",
    "\n",
    "print(f\"Student features shape: {student_features.shape}\")\n",
    "print(f\"Features created: {len(student_features.columns)} variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304d9153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average help level from main interaction data\n",
    "print(\"Calculating average help level...\")\n",
    "\n",
    "# Filter out help level 0 and calculate mean help level per student\n",
    "help_level_data = main_data[main_data['Help.Level'] > 0].groupby('Anon.Student.Id').agg({\n",
    "    'Help.Level': ['mean', 'std', 'count']\n",
    "})\n",
    "help_level_data.columns = ['avg_help_level', 'help_level_std', 'help_requests_count']\n",
    "\n",
    "# Merge with student features\n",
    "student_features = student_features.join(help_level_data, how='left')\n",
    "\n",
    "print(f\"Help level features added. Shape: {student_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2195a9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with math scores to create final dataset\n",
    "print(\"Creating final dataset...\")\n",
    "\n",
    "# Reset index to make Anon.Student.Id a column\n",
    "student_features_reset = student_features.reset_index()\n",
    "\n",
    "# Merge with math scores\n",
    "final_dataset = math_scores.merge(student_features_reset, on='Anon.Student.Id', how='inner')\n",
    "\n",
    "print(f\"Final dataset shape: {final_dataset.shape}\")\n",
    "print(f\"Students with complete data: {len(final_dataset)}\")\n",
    "\n",
    "# Display the feature names\n",
    "print(\"\\nAvailable features:\")\n",
    "feature_cols = [col for col in final_dataset.columns if col not in ['Anon.Student.Id', 'PostMath']]\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    print(f\"{i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b25643",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# LOAD TRAINED MODEL AND MAKE PREDICTIONS\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"Loading trained math model...\")\n",
    "\n",
    "# Load the saved model and feature columns\n",
    "with open('math_model.pkl', 'rb') as f:\n",
    "    model, feature_columns = pickle.load(f)\n",
    "\n",
    "print(f\"✓ Model loaded successfully!\")\n",
    "print(f\"✓ Model type: {type(model).__name__}\")\n",
    "print(f\"✓ Number of features: {len(feature_columns)}\")\n",
    "\n",
    "# Prepare features for prediction\n",
    "print(\"\\nPreparing features for prediction...\")\n",
    "\n",
    "# Select only the features used during training\n",
    "X_test = final_dataset[feature_columns].copy()\n",
    "\n",
    "# Handle missing values (same as training)\n",
    "print(\"Handling missing values...\")\n",
    "X_test = X_test.replace([np.inf, -np.inf], np.nan)\n",
    "X_test = X_test.fillna(0)  # Fill with 0 for missing values\n",
    "\n",
    "print(f\"✓ Test features shape: {X_test.shape}\")\n",
    "print(f\"✓ Features with missing values: {X_test.isnull().sum().sum()}\")\n",
    "\n",
    "# Make predictions\n",
    "print(\"\\nMaking predictions...\")\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "print(f\"✓ Predictions made for {len(predictions)} students\")\n",
    "print(f\"✓ Prediction range: {predictions.min():.2f} to {predictions.max():.2f}\")\n",
    "\n",
    "# Create results dataframe\n",
    "results_df = pd.DataFrame({\n",
    "    'Anon.Student.Id': final_dataset['Anon.Student.Id'],\n",
    "    'PostMath_Predicted': predictions\n",
    "})\n",
    "\n",
    "print(f\"\\nResults shape: {results_df.shape}\")\n",
    "print(\"\\nFirst 10 predictions:\")\n",
    "print(results_df.head(10))\n",
    "\n",
    "# Save predictions\n",
    "output_file = 'math_predictions.csv'\n",
    "results_df.to_csv(output_file, index=False)\n",
    "print(f\"\\n✓ Predictions saved to '{output_file}'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
